{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2021-11-22T18:14:47.520792Z","iopub.status.busy":"2021-11-22T18:14:47.516798Z","iopub.status.idle":"2021-11-22T18:14:49.660328Z","shell.execute_reply":"2021-11-22T18:14:49.658704Z","shell.execute_reply.started":"2021-11-22T18:14:47.520316Z"},"id":"ZvFIZlL63mXh","outputId":"512160d7-1f7e-4ca7-800c-5255fcae5813","trusted":true},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import time\n","import argparse\n","\n","import os\n","import datetime\n","import gc\n","from torch.distributions.categorical import Categorical\n","from torch.utils.data import DataLoader\n","\n","import math\n","import numpy as np\n","import torch.nn.functional as F\n","import random\n","import torch.optim as optim\n","from torch.autograd import Variable\n","from torch.optim import lr_scheduler\n","import matplotlib.pyplot as plt\n","from tqdm import tqdm_notebook\n","from torch.utils.data import Dataset\n","from torch.autograd import Variable\n","import matplotlib\n","matplotlib.use('Agg')\n","\n","# visualization \n","%matplotlib inline\n","from IPython.display import set_matplotlib_formats, clear_output\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","import warnings\n","warnings.filterwarnings(\"ignore\", category=UserWarning)\n","device = torch.device(\"cpu\"); gpu_id = -1 # select CPU\n","\n","gpu_id = '0' # select a single GPU  \n","#gpu_id = '2,3' # select multiple GPUs  \n","os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(gpu_id)  \n","if torch.cuda.is_available():\n","    device = torch.device(\"cuda\")\n","    print('GPU name: {:s}, gpu_id: {:s}'.format(torch.cuda.get_device_name(0),gpu_id))   \n","    \n","print(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-11-22T18:14:49.662778Z","iopub.status.busy":"2021-11-22T18:14:49.662344Z","iopub.status.idle":"2021-11-22T18:14:49.690403Z","shell.execute_reply":"2021-11-22T18:14:49.689609Z","shell.execute_reply.started":"2021-11-22T18:14:49.662734Z"},"id":"9x_DxlIa3mXu","trusted":true},"outputs":[],"source":["import os\n","import numpy as np\n","import torch\n","from torch.utils.data import Dataset\n","from torch.autograd import Variable\n","import matplotlib\n","matplotlib.use('Agg')\n","import matplotlib.pyplot as plt\n","\n","\n","class VehicleRoutingDataset(Dataset):\n","    def __init__(self, num_samples, input_size, max_load=20, max_demand=9):\n","        super(VehicleRoutingDataset, self).__init__()\n","\n","        if max_load < max_demand:\n","            raise ValueError(':param max_load: must be > max_demand')\n","\n","        self.num_samples = num_samples\n","        self.max_load = max_load\n","        self.max_demand = max_demand\n","\n","        # Depot location will be the first node in each\n","        locations = torch.rand((num_samples, 2, input_size + 1))\n","        self.static = locations\n","\n","        # All states will broadcast the drivers current load\n","        # Note that we only use a load between [0, 1] to prevent large\n","        # numbers entering the neural network\n","        dynamic_shape = (num_samples, 1, input_size + 1)\n","        loads = torch.full(dynamic_shape, 0)\n","\n","        # All states will have their own intrinsic demand in [1, max_demand), \n","        # then scaled by the maximum load. E.g. if load=10 and max_demand=30, \n","        # demands will be scaled to the range (0, 3)\n","        HalfofTheDemands = torch.randint(1, max_demand + 1, (num_samples,1,int(input_size / 2)))\n","        TheOtherHalfDemands = torch.randint(-1 * max_demand, 0, (num_samples,1,int(input_size / 2)))\n","        \n","        # Cat both demands with each other\n","        demands = torch.cat((HalfofTheDemands,TheOtherHalfDemands),dim = 2).squeeze(1)\n","        # Shuffling the demands tensor over the col dim\n","        demands = demands[:,torch.randperm(demands.size()[1])]\n","        # Shuffling the demands \"converting demands back into numpy array for shuffling\"\n","        # Adding zero demand for the depot \n","        demands = torch.cat((torch.zeros((num_samples,1,1)),demands.unsqueeze(1)),dim = 2)\n","        # Normlize demands with the maximum load\n","        demands = demands / float(max_load)\n","        self.dynamic = torch.cat((loads, demands), dim=1)\n","\n","    def __len__(self):\n","        return self.num_samples\n","\n","    def __getitem__(self, idx):\n","        # (static, dynamic, start_loc)\n","        return (self.static[idx], self.dynamic[idx], self.static[idx, :, 0:1])\n","\n","\n","def reward_fn(static, tour_indices):\n","    \n","    \"\"\"\n","    Euclidean distance between all cities / nodes given by tour_indices\n","    \"\"\"\n","    # Convert the indices back into a tour\n","    idx = tour_indices.unsqueeze(1).expand(-1, static.size(1), -1)\n","    tour = torch.gather(static.data, 2, idx).permute(0, 2, 1)\n","\n","    # Ensure we're always returning to the depot - note the extra concat\n","    # won't add any extra loss, as the euclidean distance between consecutive\n","    # points is 0\n","    start = static.data[:, :, 0].unsqueeze(1)\n","    y = torch.cat((start, tour, start), dim=1)\n","\n","    # Euclidean distance between each consecutive point\n","    tour_len = torch.sqrt(torch.sum(torch.pow(y[:, :-1] - y[:, 1:], 2), dim=2))\n","\n","    return tour_len.sum(1).detach()\n","\n","\n","def render_fn(static, tour_indices, save_path):\n","    \"\"\"Plots the found solution.\"\"\"\n","\n","    plt.close('all')\n","    num_plots = 3 if int(np.sqrt(len(tour_indices))) >= 3 else 1\n","    _, axes = plt.subplots(nrows=num_plots, ncols=num_plots,sharex='col', sharey='row')\n","    if num_plots == 1:\n","        axes = [[axes]]\n","    axes = [a for ax in axes for a in ax]\n","    for i, ax in enumerate(axes):\n","\n","        # Convert the indices back into a tour\n","        idx = tour_indices[i]\n","        if len(idx.size()) == 1:\n","            idx = idx.unsqueeze(0)\n","\n","        idx = idx.expand(static.size(1), -1)\n","        data = torch.gather(static[i].data, 1, idx).cpu().numpy()\n","\n","        start = static[i, :, 0].cpu().data.numpy()\n","        x = np.hstack((start[0], data[0], start[0]))\n","        y = np.hstack((start[1], data[1], start[1]))\n","\n","        # Assign each subtour a different colour & label in order traveled\n","        idx = np.hstack((0, tour_indices[i].cpu().numpy().flatten(), 0))\n","        where = np.where(idx == 0)[0]\n","\n","        for j in range(len(where) - 1):\n","\n","            low = where[j]\n","            high = where[j + 1]\n","\n","            if low + 1 == high:\n","                continue\n","\n","            ax.plot(x[low: high + 1], y[low: high + 1], zorder=1, label=j)\n","\n","        ax.legend(loc=\"upper right\", fontsize=3, framealpha=0.5)\n","        ax.scatter(x, y, s=4, c='r', zorder=2)\n","        ax.scatter(x[0], y[0], s=20, c='k', marker='*', zorder=3)\n","\n","        ax.set_xlim(0, 1)\n","        ax.set_ylim(0, 1)\n","\n","    plt.tight_layout()\n","    plt.savefig(save_path, bbox_inches='tight', dpi=200)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-11-22T18:14:49.693799Z","iopub.status.busy":"2021-11-22T18:14:49.693377Z","iopub.status.idle":"2021-11-22T18:14:49.707129Z","shell.execute_reply":"2021-11-22T18:14:49.706350Z","shell.execute_reply.started":"2021-11-22T18:14:49.693735Z"},"id":"C_qKmVDf3mXw","trusted":true},"outputs":[],"source":["import torch\n","import time\n","\n","def update_state(demand,dynamic_capcity,selected,c = 0):#dynamic_capcity(num,1)\n","    \n","    depot  =  selected.squeeze(-1).eq(0) # Is there a group to access the depot\n","    current_demand = torch.gather(demand,1,selected)\n","    dynamic_capcity = dynamic_capcity - current_demand\n","    \n","    if depot.any():\n","        dynamic_capcity[depot.nonzero().squeeze()] = c\n","        \n","    return dynamic_capcity.detach()#(bach_size,1)\n","\n","\n","def update_mask(demand,capcity,selected,mask,i):\n","    \n","    # If there is a route to select a depot, mask the depot, otherwise it will not mask the depot\n","    go_depot = selected.squeeze(-1).eq(0)\n","    mask1 = mask.scatter(1, selected.expand(mask.size(0), -1), 1)\n","\n","    if capcity.gt(1).any():\n","        print(\"warning\")\n","\n","    if (~go_depot).any():\n","        mask1[(~go_depot).nonzero(),0] = 0\n","\n","    if i+1 > (demand.size(1) / 2):\n","        is_done = (mask1[:, 1:].sum(1) >= (demand.size(1) - 1)).float()\n","        combined = is_done.gt(0)\n","        mask1[combined.nonzero(), 0] = 0\n","\n","    # Mask any city if its demand is greater than the current truck's cap\n","    a = demand > capcity + 1e-3\n","    # Mask any city if its demand and the remaining capcity are greater than the truck limit \"1\"\n","    b = torch.neg(demand.masked_fill(demand.gt(0), 0.)) + capcity > 1\n","    mask = a + mask1 + b\n","    \"\"\"\n","    print(\"mask\",mask)\n","    print(\"mask1\",mask1)\n","    print('demand',demand)\n","    print('capcity',capcity)\n","    print('*************************')\n","    \"\"\"\n","    return mask.detach(),mask1.detach()"]},{"cell_type":"markdown","metadata":{},"source":["# HPN for Random PDP"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-11-22T18:14:49.711307Z","iopub.status.busy":"2021-11-22T18:14:49.711064Z","iopub.status.idle":"2021-11-22T18:14:49.786990Z","shell.execute_reply":"2021-11-22T18:14:49.786054Z","shell.execute_reply.started":"2021-11-22T18:14:49.711264Z"},"id":"D6ststo33mXx","trusted":true},"outputs":[],"source":["class Transformer_encoder_net(nn.Module):\n","    \"\"\"\n","    Encoder network based on self-attention transformer\n","    Inputs :  \n","      h of size      (bsz, nb_nodes+1, dim_emb)    batch of input cities\n","    Outputs :  \n","      h of size      (bsz, nb_nodes+1, dim_emb)    batch of encoded cities\n","      score of size  (bsz, nb_nodes+1, nb_nodes+1) batch of attention scores\n","    \"\"\"\n","    \n","    def __init__(self, nb_layers, dim_emb, nb_heads, dim_ff, batchnorm):\n","        super(Transformer_encoder_net, self).__init__()\n","        assert dim_emb == nb_heads* (dim_emb//nb_heads) # check if dim_emb is divisible by nb_heads\n","        self.MHA_layers = nn.ModuleList( [nn.MultiheadAttention(dim_emb, nb_heads) for _ in range(nb_layers)] )\n","        self.linear1_layers = nn.ModuleList( [nn.Linear(dim_emb, dim_ff) for _ in range(nb_layers)] )\n","        self.linear2_layers = nn.ModuleList( [nn.Linear(dim_ff, dim_emb) for _ in range(nb_layers)] )   \n","        if batchnorm:\n","            self.norm1_layers = nn.ModuleList( [nn.BatchNorm1d(dim_emb) for _ in range(nb_layers)] )\n","            self.norm2_layers = nn.ModuleList( [nn.BatchNorm1d(dim_emb) for _ in range(nb_layers)] )\n","        else:\n","            self.norm1_layers = nn.ModuleList( [nn.LayerNorm(dim_emb) for _ in range(nb_layers)] )\n","            self.norm2_layers = nn.ModuleList( [nn.LayerNorm(dim_emb) for _ in range(nb_layers)] )\n","        self.nb_layers = nb_layers\n","        self.nb_heads = nb_heads\n","        self.batchnorm = batchnorm\n","        \n","    def forward(self, h):      \n","        # PyTorch nn.MultiheadAttention requires input size (seq_len, bsz, dim_emb) \n","        h = h.transpose(0,1) # size(h)=(nb_nodes, bsz, dim_emb)  \n","        # L layers\n","        for i in range(self.nb_layers):\n","            h_rc = h # residual connection, size(h_rc)=(nb_nodes, bsz, dim_emb)\n","            h, score = self.MHA_layers[i](h, h, h) # size(h)=(nb_nodes, bsz, dim_emb), size(score)=(bsz, nb_nodes, nb_nodes)\n","            # add residual connection\n","            \n","            h = h_rc + h # size(h)=(nb_nodes, bsz, dim_emb)\n","            if self.batchnorm:\n","                # Pytorch nn.BatchNorm1d requires input size (bsz, dim, seq_len)\n","                h = h.permute(1,2,0).contiguous() # size(h)=(bsz, dim_emb, nb_nodes)\n","                h = self.norm1_layers[i](h)       # size(h)=(bsz, dim_emb, nb_nodes)\n","                h = h.permute(2,0,1).contiguous() # size(h)=(nb_nodes, bsz, dim_emb)\n","            else:\n","                h = self.norm1_layers[i](h)       # size(h)=(nb_nodes, bsz, dim_emb) \n","            # feedforward\n","            h_rc = h # residual connection\n","            h = self.linear2_layers[i](torch.relu(self.linear1_layers[i](h)))\n","            h = h_rc + h # size(h)=(nb_nodes, bsz, dim_emb)\n","            if self.batchnorm:\n","                h = h.permute(1,2,0).contiguous() # size(h)=(bsz, dim_emb, nb_nodes)\n","                h = self.norm2_layers[i](h)       # size(h)=(bsz, dim_emb, nb_nodes)\n","                h = h.permute(2,0,1).contiguous() # size(h)=(nb_nodes, bsz, dim_emb)\n","            else:\n","                h = self.norm2_layers[i](h) # size(h)=(nb_nodes, bsz, dim_emb)\n","        # Transpose h\n","        h = h.transpose(0,1) # size(h)=(bsz, nb_nodes, dim_emb)\n","        return h, score\n","\n","class Attention(nn.Module):\n","    def __init__(self, n_hidden):\n","        super(Attention, self).__init__()\n","        self.size = 0\n","        self.batch_size = 0\n","        self.dim = n_hidden\n","        \n","        v  = torch.FloatTensor(n_hidden)\n","        self.v  = nn.Parameter(v)\n","        self.v.data.uniform_(-1/math.sqrt(n_hidden), 1/math.sqrt(n_hidden))\n","        \n","        # parameters for pointer attention\n","        self.Wref = nn.Linear(n_hidden, n_hidden)\n","        self.Wq = nn.Linear(n_hidden, n_hidden)\n","    \n","    \n","    def forward(self, q, ref):       # query and reference\n","        self.batch_size = q.size(0)\n","        self.size = int(ref.size(0) / self.batch_size)\n","        q = self.Wq(q)     # (B, dim)\n","        ref = self.Wref(ref)\n","        ref = ref.view(self.batch_size, self.size, self.dim)  # (B, size, dim)\n","        \n","        q_ex = q.unsqueeze(1).repeat(1, self.size, 1) # (B, size, dim)\n","        # v_view: (B, dim, 1)\n","        v_view = self.v.unsqueeze(0).expand(self.batch_size, self.dim).unsqueeze(2)\n","        \n","        # (B, size, dim) * (B, dim, 1)\n","        u = torch.bmm(torch.tanh(q_ex + ref), v_view).squeeze(2)\n","        \n","        return u, ref\n","    \n","class LSTM(nn.Module):\n","    def __init__(self, n_hidden):\n","        super(LSTM, self).__init__()\n","        \n","        # parameters for input gate\n","        self.Wxi = nn.Linear(n_hidden, n_hidden)    # W(xt)\n","        self.Whi = nn.Linear(n_hidden, n_hidden)    # W(ht)\n","        self.wci = nn.Linear(n_hidden, n_hidden)    # w(ct)\n","        \n","        # parameters for forget gate\n","        self.Wxf = nn.Linear(n_hidden, n_hidden)    # W(xt)\n","        self.Whf = nn.Linear(n_hidden, n_hidden)    # W(ht)\n","        self.wcf = nn.Linear(n_hidden, n_hidden)    # w(ct)\n","        \n","        # parameters for cell gate\n","        self.Wxc = nn.Linear(n_hidden, n_hidden)    # W(xt)\n","        self.Whc = nn.Linear(n_hidden, n_hidden)    # W(ht)\n","        \n","        # parameters for forget gate\n","        self.Wxo = nn.Linear(n_hidden, n_hidden)    # W(xt)\n","        self.Who = nn.Linear(n_hidden, n_hidden)    # W(ht)\n","        self.wco = nn.Linear(n_hidden, n_hidden)    # w(ct)\n","    \n","    \n","    def forward(self, x, h, c):       # query and reference\n","        \n","        # input gate\n","        i = torch.sigmoid(self.Wxi(x) + self.Whi(h) + self.wci(c))\n","        # forget gate\n","        f = torch.sigmoid(self.Wxf(x) + self.Whf(h) + self.wcf(c))\n","        # cell gate\n","        c = f * c + i * torch.tanh(self.Wxc(x) + self.Whc(h))\n","        # output gate\n","        o = torch.sigmoid(self.Wxo(x) + self.Who(h) + self.wco(c))\n","        \n","        h = o * torch.tanh(c)\n","        \n","        return h, c\n","\n","class HPN_PDP(nn.Module):\n","    def __init__(self, n_feature, n_hidden):\n","        super(HPN_PDP, self).__init__()\n","        \n","        self.city_size = 0\n","        self.batch_size = 0\n","        self.dim = n_hidden\n","        # pointer layer\n","        self.pointer = Attention(n_hidden)\n","        self.TransPointer = Attention(n_hidden)\n","        \n","        # LSTM encoder\n","        self.encoder = LSTM(n_hidden)\n","        \n","        # trainable first hidden input\n","        h0 = torch.FloatTensor(n_hidden)\n","        c0 = torch.FloatTensor(n_hidden)\n","        \n","        self.h0 = nn.Parameter(h0)\n","        self.c0 = nn.Parameter(c0)\n","        self.h0.data.uniform_(-1/math.sqrt(n_hidden), 1/math.sqrt(n_hidden))\n","        self.c0.data.uniform_(-1/math.sqrt(n_hidden), 1/math.sqrt(n_hidden))\n","        \n","        r1 = torch.ones(1)\n","        r2 = torch.ones(1)\n","        r3 = torch.ones(1)\n","        self.r1 = nn.Parameter(r1)\n","        self.r2 = nn.Parameter(r2)\n","        self.r3 = nn.Parameter(r3)\n","        \n","        # embedding for the feature tensor\n","        self.embedding_all = nn.Linear(2 * n_feature  , n_hidden)\n","        \n","        self.fc = nn.Linear(n_hidden + 1, n_hidden, bias=False)\n","        self.fc1 = nn.Linear(n_hidden, n_hidden, bias=False)\n","        \n","        # transformer's encoder\n","        self.Transembedding_all = Transformer_encoder_net(6, 128, 8, 512, batchnorm=True)\n","        \n","        # weights for GNN\n","        self.W1 = nn.Linear(n_hidden, n_hidden)\n","        self.W2 = nn.Linear(n_hidden, n_hidden)\n","        self.W3 = nn.Linear(n_hidden, n_hidden)\n","        \n","        # aggregation function for GNN\n","        self.agg_1 = nn.Linear(n_hidden, n_hidden)\n","        self.agg_2 = nn.Linear(n_hidden, n_hidden)\n","        self.agg_3 = nn.Linear(n_hidden, n_hidden)\n","    \n","    \n","    def forward(self,static, dynamic,deterministic = False,decoder_input = None):\n","        \n","        \"\"\"\n","        Parameters\n","        ----------\n","        static: Array of size (batch_size, feats, num_cities)\n","            Defines the elements to consider as static. For the TSP, this could be\n","            things like the (x, y) coordinates, which won't change\n","        dynamic: Array of size (batch_size, feats, num_cities)\n","            Defines the elements to consider as static. For the VRP, this can be\n","            things like the (load, demand) of each city. If there are no dynamic\n","            elements, this can be set to None\n","        decoder_input: Array of size (batch_size, num_feats)\n","            Defines the outputs for the decoder. Currently, we just use the\n","            static elements (e.g. (x, y) coordinates), but this can technically\n","            be other things as well\n","        \"\"\"\n","            \n","        tour_idx, tour_logp = [], []\n","        self.batch_size, self.city_size,input_size= static.size() # (B,size,feat)\n","        # Always use a mask - if no function is provided, we don't update it\n","        \n","        mask1 = torch.zeros((self.batch_size, self.city_size)).to(device)\n","        mask = torch.zeros((self.batch_size, self.city_size)).to(device)\n","        \n","        dynamic_capcity = dynamic[:,0,0].view(self.batch_size,-1)#bat_size\n","        demands = dynamic[:,:,1].view(self.batch_size, self.city_size)#（batch_size,seq_len）\n","        \n","        # Handle hidden and cell state for LSTM\n","        h0 = self.h0.unsqueeze(0).expand(self.batch_size, self.dim)\n","        c0 = self.c0.unsqueeze(0).expand(self.batch_size, self.dim)\n","        h0 = h0.unsqueeze(0).contiguous()\n","        c0 = c0.unsqueeze(0).contiguous()\n","        # let h0, c0 be the hidden variable of first turn\n","        h = h0.squeeze(0)\n","        c = c0.squeeze(0)\n","        \n","        max_steps = 2 * self.city_size\n","        # Special Embedding for depot\n","        # Cat both feature for embedding\n","        all_feature = torch.cat((static,demands.unsqueeze(2)),dim = 2) \n","        all_feature = torch.cat((all_feature,torch.cdist(static,decoder_input[:,:2].unsqueeze(1),p=2)),dim = 2)\n","        \n","        # init embedding for feature vector\n","        context = self.embedding_all(all_feature) #(B,size,n_hidden)\n","        # ==================================================\n","        # graph neural network encoder & transformer encoder\n","        # ==================================================\n","        Trans_hidden,_ = self.Transembedding_all(context) # (B,size,n_hidden)\n","        TransPooled  = Trans_hidden.mean(dim=1)\n","        #Trans_hidden = Trans_hidden.reshape(-1, self.dim) # (B*size,n_hidden)\n","        context = context.reshape(-1, self.dim)           # (B*size,n_hidden)\n","\n","        # GNN layers\n","        context = self.r1 * self.W1(context) + (1-self.r1) * F.relu(self.agg_1(context/(self.city_size-1)))\n","        context = self.r2 * self.W2(context) + (1-self.r2) * F.relu(self.agg_2(context/(self.city_size-1)))\n","        context = self.r3 * self.W3(context) + (1-self.r3) * F.relu(self.agg_3(context/(self.city_size-1)))\n","        contextPooled = context.reshape(self.batch_size,self.city_size,self.dim).mean(dim=1)\n","        pool = TransPooled + contextPooled\n","\n","        index = torch.zeros(self.batch_size).to(device).long()\n","        \n","        for t in range(max_steps):\n","            if not mask1[:, 1:].eq(0).any():\n","                break\n","            if t == 0:                \n","                _input = Trans_hidden[:, 0, :]  # depot\n","                \n","            decoder_input = torch.cat((_input,dynamic_capcity),dim = 1)\n","            decoder_input = self.fc(decoder_input)\n","            \n","            pool = self.fc1(pool)\n","            decoder_input = decoder_input + pool\n","            \n","            if t == 0:\n","                mask, mask1 = update_mask(demands, dynamic_capcity, index.unsqueeze(-1), mask1, t)\n","                \n","            # LSTM encoder\n","            h, c = self.encoder(decoder_input, h, c)\n","            # pointer\n","            u1, _ = self.pointer(h, context.reshape(-1, self.dim))\n","            u2 ,_ = self.TransPointer(h,Trans_hidden.reshape(-1, self.dim))\n","            u = u1 + u2\n","            u = 10 * torch.tanh(u)\n","            u = u.masked_fill(mask.bool(), float(\"-inf\"))\n","            probs = F.softmax(u, dim=1)\n","            \n","            # When training, sample the next step according to its probability.\n","            # During testing, we can take the greedy approach and choose highest\n","            if  deterministic:\n","                prob, index = torch.max(probs,dim=1)  # Greedy\n","                logp = prob.log()\n","            else:\n","                # Sampling\n","                m = torch.distributions.Categorical(probs)\n","                index = m.sample()\n","                logp = m.log_prob(index)\n","                \n","            is_done = (mask1[:, 1:].sum(1) >= (Trans_hidden.size(1) - 1)).float()\n","            logp = logp * (1. - is_done)\n","                \n","            # After visiting a node update the dynamic representation\n","            #dynamic = update_fn(dynamic.permute(0,2,1), ptr.data).permute(0,2,1)\n","            # Since we compute the VRP in minibatches, some tours may have\n","            # number of stops. We force the vehicles to remain at the depot \n","            # in these cases, and logp := 0\n","            #is_done = dynamic.permute(0,2,1)[:, 1].sum(1).eq(0).float()\n","            #logp = logp * (1. - is_done)\n","            \n","            dynamic_capcity = update_state(demands, dynamic_capcity, index.unsqueeze(-1),c = 0.5)\n","            mask, mask1 = update_mask(demands, dynamic_capcity, index.unsqueeze(-1), mask1, t)\n","            \n","            # And update the mask so we don't re-visit if we don't need to\n","            tour_logp.append(logp.unsqueeze(1))\n","            tour_idx.append(index.data.unsqueeze(1))\n","            \n","            #mask = mask_fn(ptr_prev, dynamic.permute(0,2,1), ptr.data)\n","            _input = torch.gather(Trans_hidden, 1,\n","                                  index.unsqueeze(-1).unsqueeze(-1).expand(Trans_hidden.size(0), -1,\n","                                                                           Trans_hidden.size(2))).squeeze(1)\n","            \n","        tour_idx = torch.cat(tour_idx, dim=1)  # (batch_size, seq_len)\n","        tour_logp = torch.cat(tour_logp, dim=1)  # (batch_size, seq_len)\n","        return tour_idx, tour_logp\n","    \n","def validate(data_loader, Critic, reward_fn, render_fn=None, save_dir='.',num_plot=5):\n","    \"\"\"Used to monitor progress on a validation set & optionally plot solution.\"\"\"\n","    if not os.path.exists(save_dir):\n","        os.makedirs(save_dir)\n","        \n","    rewards = []\n","    for batch_idx, batch in enumerate(data_loader):\n","        with torch.no_grad():\n","            static, dynamic, x0 = batch\n","            static  = torch.movedim(static,1,2).to(device) # (B,size,feat)\n","            dynamic = torch.movedim(dynamic,1,2).to(device) # (B,size,feat)\n","            x0      = torch.movedim(x0,1,2).squeeze(1).to(device) if len(x0) > 0 else None  # (B,size,feat)\n","\n","            with torch.no_grad():\n","                tour_indices, _ = Critic(static, dynamic, decoder_input = x0,deterministic=True)\n","\n","            reward = reward_fn(static.permute(0,2,1), tour_indices).mean().item()\n","            rewards.append(reward)\n","\n","            if render_fn is not None and batch_idx < num_plot:\n","                name = 'batch%d_%2.4f.png'%(batch_idx, reward)\n","                path = os.path.join(save_dir, name)\n","                render_fn(static.permute(0,2,1), tour_indices, path)\n","    return np.mean(rewards)"]},{"cell_type":"markdown","metadata":{"id":"NIuJiHBo3mX1"},"source":["# Training"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-11-22T18:14:49.791193Z","iopub.status.busy":"2021-11-22T18:14:49.790772Z","iopub.status.idle":"2021-11-23T02:55:28.893198Z","shell.execute_reply":"2021-11-23T02:55:28.892317Z","shell.execute_reply.started":"2021-11-22T18:14:49.791163Z"},"id":"RaQiVFNW3mX5","outputId":"63ffb291-201a-4944-a1a8-3796ec00ece9","trusted":true},"outputs":[],"source":["########################\n","# Training Hyperparameters\n","#######################\n","# Dynamic ones\n","size = 20                 # Size of the CVRP Problem\n","max_load = 30             # Max load for the truck\n","MAX_DEMAND = 9            # Max Demand for each agent\n","\n","# Fixed Parameter for all sizes\n","TOL  =  1e-3              # Tolerance for Actor-critic \n","TINY =  1e-15\n","learn_rate = 1e-4         # learning rate\n","batch_size = 512         # batch_size\n","train_size = 512         \n","compare_size = 512       \n","\n","valid_size = 10000         # validation size\n","valid_batch = 10000\n","\n","B_valLoop = 20\n","steps = 2500              # training steps\n","n_epoch = 100             # epochs\n","\n","print('=========================')\n","print('prepare to train')\n","print('=========================')\n","print('Hyperparameters:')\n","print('size', size)\n","print('learning rate', learn_rate)\n","print('batch size', batch_size)\n","print('validation size', valid_size)\n","print('steps', steps)\n","print('epoch', n_epoch)\n","print('=========================')\n","\n","###################\n","# Instantiate a training network and a baseline network\n","###################\n","try: \n","    del Actor # remove existing model\n","    del Critic # remove existing model\n","except:\n","    pass\n","\n","valid_data = VehicleRoutingDataset(valid_size,size,max_load,MAX_DEMAND)\n","valid_loader = DataLoader(valid_data, valid_batch, False, num_workers=0)\n","Actor  = HPN_PDP(n_feature=2, n_hidden=128)\n","Critic = HPN_PDP(n_feature=2, n_hidden=128)\n","optimizer = optim.Adam(Actor.parameters(), lr=learn_rate)\n","\n","# Putting Critic model on the eval mode\n","Actor = Actor.to(device)\n","Critic = Critic.to(device)\n","Critic.eval()\n","\n","# uncomment these lines if trained with multiple GPUs\n","print(torch.cuda.device_count())\n","if torch.cuda.device_count()>1:\n","    Actor = nn.DataParallel(Actor)\n","    Critic = nn.DataParallel(Critic)\n","# uncomment these lines if trained with multiple GPUs\n","\n","########################\n","# Remember to first initialize the model and optimizer, then load the dictionary locally.\n","#######################\n","\n","epoch_ckpt = 0\n","tot_time_ckpt = 0\n","\n","val_mean = []\n","val_std  = []\n","\n","plot_performance_train = []\n","plot_performance_baseline = []\n","\n","################################################################# Restart Training With Check Points ######################################################\n","#********************************************# Uncomment these lines to re-start training with saved checkpoint #********************************************#\n","#************************************************************************************************************************************************************#\n","\"\"\"\n","checkpoint_file = \"../input/pdpsize50/checkpoint_21-11-22--01-27-17-n50-gpu0.pkl\"\n","checkpoint = torch.load(checkpoint_file, map_location=device)\n","epoch_ckpt = checkpoint['epoch'] + 1\n","tot_time_ckpt = checkpoint['tot_time']\n","plot_performance_train = checkpoint['plot_performance_train']\n","plot_performance_baseline = checkpoint['plot_performance_baseline']\n","Critic.load_state_dict(checkpoint['model_baseline'])\n","Actor.load_state_dict(checkpoint['model_train'])\n","optimizer.load_state_dict(checkpoint['optimizer'])\n","\n","print('Re-start training with saved checkpoint file={:s}\\n  Checkpoint at epoch= {:d} and time={:.3f}min\\n'.format(checkpoint_file,epoch_ckpt-1,tot_time_ckpt/60))\n","del checkpoint\n","\"\"\"\n","#*************************************************************************************************************************************************************#\n","#*********************************************# Uncomment these lines to re-start training with saved checkpoint #********************************************#\n","\n","\n","###################\n","#  Main training loop \n","###################\n","start_training_time = time.time()\n","time_stamp = datetime.datetime.now().strftime(\"%y-%m-%d--%H-%M-%S\")\n","zero_to_bsz = torch.arange(batch_size, device=device) # [0,1,...,bsz-1]\n","R = 0\n","C = 0\n","for epoch in range(0,n_epoch):\n","    # re-start training with saved checkpoint\n","    epoch += epoch_ckpt\n","    \n","    ###################\n","    # Train model for one epoch\n","    ###################\n","    start = time.time()\n","    Actor.train()\n","    \n","    for i in range(1,steps+1):\n","        \n","        train_data = VehicleRoutingDataset(train_size,size,max_load,MAX_DEMAND)\n","        train_loader = DataLoader(train_data, batch_size, False, num_workers=0)\n","        for batch_idx, batch in enumerate(train_loader):\n","\n","            static, dynamic, x0 = batch\n","            static  = torch.movedim(static,1,2).to(device) # (B,size,feat)\n","            dynamic = torch.movedim(dynamic,1,2).to(device) # (B,size,feat)\n","            x0      = torch.movedim(x0,1,2).squeeze(1).to(device) if len(x0) > 0 else None\n","            \n","            tour_indices, logprobs = Actor(static, dynamic,decoder_input = x0,deterministic=False)\n","            R = reward_fn(static.permute(0,2,1), tour_indices)\n","            \n","            with torch.no_grad():\n","                tour_indices, _ = Critic(static, dynamic, decoder_input = x0,deterministic=True)\n","            C = reward_fn(static.permute(0,2,1), tour_indices)\n","            \n","            ###################\n","            # Loss and backprop handling \n","            ###################\n","            loss = torch.mean((R - C) * logprobs.sum(dim=1))\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","            \n","        if i % 50 == 0:\n","            print(\"epoch:{}, batch:{}/{}, reward:{}\".format(epoch, i, steps, R.mean().item()))\n","\n","        time_one_epoch = time.time() - start\n","        time_tot = time.time() - start_training_time + tot_time_ckpt\n","\n","    ###################\n","    # Evaluate train model and baseline on 1k random TSP instances\n","    ###################\n","    Actor.eval()\n","    \n","    mean_tour_length_actor = 0\n","    mean_tour_length_critic = 0\n","\n","    for step in range(0,B_valLoop):\n","        # compute tour for model and baseline\n","        comp_data = VehicleRoutingDataset(compare_size,size,max_load,MAX_DEMAND)\n","        comp_loader = DataLoader(comp_data, compare_size, False, num_workers=0)\n","        \n","        for batch_idx, batch in enumerate(comp_loader):\n","            \n","            static, dynamic, x0 = batch\n","            static  = torch.movedim(static,1,2).to(device) # (B,size,feat)\n","            dynamic = torch.movedim(dynamic,1,2).to(device) # (B,size,feat)\n","            x0      = torch.movedim(x0,1,2).squeeze(1).to(device) if len(x0) > 0 else None  # (B,size,feat)\n","            \n","            with torch.no_grad():\n","                tour_indicesActor, _ = Actor(static, dynamic, decoder_input = x0,deterministic =  True)\n","                tour_indicesCritic, _ = Critic(static, dynamic, decoder_input = x0,deterministic = True)\n","            \n","        R = reward_fn(static.permute(0,2,1), tour_indicesActor)\n","        C = reward_fn(static.permute(0,2,1), tour_indicesCritic)\n","                \n","        mean_tour_length_actor  += R.mean().item()\n","        mean_tour_length_critic += C.mean().item()\n","        \n","    mean_tour_length_actor  =  mean_tour_length_actor  / B_valLoop\n","    mean_tour_length_critic =  mean_tour_length_critic / B_valLoop\n","\n","    # evaluate train model and baseline and update if train model is better\n","    update_baseline = mean_tour_length_actor + TOL < mean_tour_length_critic\n","    print('Avg Actor {} --- Avg Critic {}'.format(mean_tour_length_actor,mean_tour_length_critic))\n","    if update_baseline:\n","        Critic.load_state_dict(Actor.state_dict())\n","        print('My actor is going on the right road Hallelujah :) Updated')\n","        \n","    ###################\n","    # val train model and baseline on 1k random TSP instances\n","    ###################\n","    \n","    # Saving checkpoint and valied images\n","    checkpoint_dir = os.path.join(\"checkpoint\")\n","    if not os.path.exists(checkpoint_dir):\n","        os.makedirs(checkpoint_dir)\n","     \n","    with torch.no_grad():\n","        tour_len = validate(valid_loader, Critic, reward_fn, render_fn,checkpoint_dir, num_plot=5)\n","    print('validation tour length:', tour_len)\n","        \n","    # For checkpoint\n","    plot_performance_train.append([(epoch+1), mean_tour_length_actor])\n","    plot_performance_baseline.append([(epoch+1), mean_tour_length_critic])\n","    \n","    # Print and save in txt file\n","    mystring_min = 'Epoch: {:d}, epoch time: {:.3f}min, tot time: {:.3f}day, L_actor: {:.3f}, L_critic: {:.3f}, update: {}'.format(\n","        epoch, time_one_epoch/60, time_tot/86400, mean_tour_length_actor, mean_tour_length_critic, update_baseline)\n","    \n","    print(mystring_min)\n","    print('Save Checkpoints')\n","        \n","    torch.save({\n","        'epoch': epoch,\n","        'time': time_one_epoch,\n","        'tot_time': time_tot,\n","        'loss': loss.item(),\n","        'plot_performance_train': plot_performance_train,\n","        'plot_performance_baseline': plot_performance_baseline,\n","        'mean_tour_length_val': tour_len,\n","        'model_baseline': Critic.state_dict(),\n","        'model_train': Actor.state_dict(),\n","        'optimizer': optimizer.state_dict(),\n","        }, '{}.pkl'.format(checkpoint_dir + \"/checkpoint_\" + time_stamp + \"-n{}\".format(size) + \"-gpu{}\".format(gpu_id)))"]},{"cell_type":"markdown","metadata":{},"source":["# Simple Test"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2021-11-23T02:55:28.894212Z","iopub.status.idle":"2021-11-23T02:55:28.896798Z","shell.execute_reply":"2021-11-23T02:55:28.896596Z","shell.execute_reply.started":"2021-11-23T02:55:28.896568Z"},"id":"eCdLTr6E3mX6","trusted":true},"outputs":[],"source":["# Saving checkpoint and valied images\n","checkpoint_dir = os.path.join(\"checkpoint\")\n","if not os.path.exists(checkpoint_dir):\n","    os.makedirs(checkpoint_dir)\n","valid_data = VehicleRoutingDataset(1000,size,max_load,MAX_DEMAND)\n","valid_loader = DataLoader(valid_data, 1000, False, num_workers=0)\n","with torch.no_grad():\n","    tour_len = validate(valid_loader, Critic, reward_fn, render_fn,checkpoint_dir, num_plot=5)\n","print('validation tour length:', tour_len)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":4}
